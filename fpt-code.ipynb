{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2439818,"sourceType":"datasetVersion","datasetId":1476403}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/AmirEspahbodi/FPT.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-01T16:15:56.268008Z","iopub.execute_input":"2025-02-01T16:15:56.268376Z","iopub.status.idle":"2025-02-01T16:15:56.935761Z","shell.execute_reply.started":"2025-02-01T16:15:56.268343Z","shell.execute_reply":"2025-02-01T16:15:56.934606Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'FPT'...\nremote: Enumerating objects: 214, done.\u001b[K\nremote: Counting objects: 100% (214/214), done.\u001b[K\nremote: Compressing objects: 100% (135/135), done.\u001b[K\nremote: Total 214 (delta 111), reused 170 (delta 73), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (214/214), 774.83 KiB | 16.84 MiB/s, done.\nResolving deltas: 100% (111/111), done.\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"!git -C FPT pull","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T16:02:15.535877Z","iopub.execute_input":"2025-02-01T16:02:15.536198Z","iopub.status.idle":"2025-02-01T16:02:16.149336Z","shell.execute_reply.started":"2025-02-01T16:02:15.536172Z","shell.execute_reply":"2025-02-01T16:02:16.148219Z"}},"outputs":[{"name":"stdout","text":"remote: Enumerating objects: 11, done.\u001b[K\nremote: Counting objects: 100% (11/11), done.\u001b[K\nremote: Compressing objects: 100% (1/1), done.\u001b[K\nremote: Total 6 (delta 5), reused 6 (delta 5), pack-reused 0 (from 0)\u001b[K\nUnpacking objects: 100% (6/6), 569 bytes | 284.00 KiB/s, done.\nFrom https://github.com/AmirEspahbodi/FPT\n   66d1dab..60e402b  main       -> origin/main\nUpdating 66d1dab..60e402b\nFast-forward\n configs/dataset/covid.yaml      | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n configs/dataset/customized.yaml | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n 2 files changed, 4 insertions(+), 4 deletions(-)\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"!pip install -q condacolab\nimport condacolab\ncondacolab.install()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T15:59:03.343184Z","iopub.execute_input":"2025-02-02T15:59:03.343476Z","iopub.status.idle":"2025-02-02T15:59:20.991534Z","shell.execute_reply.started":"2025-02-02T15:59:03.343449Z","shell.execute_reply":"2025-02-02T15:59:20.990757Z"}},"outputs":[{"name":"stdout","text":"â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\nğŸ“¦ Installing...\nğŸ“Œ Adjusting configuration...\nğŸ©¹ Patching environment...\nâ² Done in 0:00:13\nğŸ” Restarting kernel...\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!conda create -n fpt_py38 python=3.8 -y\n!conda run -n fpt_py38 python --version","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!conda run -n fpt_py38 pip install -r FPT/requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T16:11:07.151611Z","iopub.execute_input":"2025-02-02T16:11:07.151927Z","iopub.status.idle":"2025-02-02T16:13:43.598211Z","shell.execute_reply.started":"2025-02-02T16:11:07.151902Z","shell.execute_reply":"2025-02-02T16:13:43.597361Z"}},"outputs":[{"name":"stdout","text":"Collecting tqdm==4.50.2 (from -r FPT/requirements.txt (line 1))\n  Downloading tqdm-4.50.2-py2.py3-none-any.whl.metadata (55 kB)\nCollecting torch==2.0.0 (from -r FPT/requirements.txt (line 2))\n  Downloading torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl.metadata (24 kB)\nCollecting PyYAML==6.0 (from -r FPT/requirements.txt (line 3))\n  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\nCollecting torcheval==0.0.6 (from -r FPT/requirements.txt (line 4))\n  Downloading torcheval-0.0.6-py3-none-any.whl.metadata (8.8 kB)\nCollecting hydra-core==1.1.0 (from -r FPT/requirements.txt (line 5))\n  Downloading hydra_core-1.1.0-py3-none-any.whl.metadata (4.1 kB)\nCollecting safetensors==0.3.2 (from -r FPT/requirements.txt (line 6))\n  Downloading safetensors-0.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\nCollecting torchvision==0.15.1 (from -r FPT/requirements.txt (line 7))\n  Downloading torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl.metadata (11 kB)\nCollecting transformers==4.29.1 (from -r FPT/requirements.txt (line 8))\n  Downloading transformers-4.29.1-py3-none-any.whl.metadata (112 kB)\nCollecting filelock (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting typing-extensions (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\nCollecting sympy (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\nCollecting networkx (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\nCollecting jinja2 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.0.0 (from torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nCollecting torchtnt>=0.0.5 (from torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading torchtnt-0.2.4-py3-none-any.whl.metadata (3.1 kB)\nCollecting omegaconf==2.1.* (from hydra-core==1.1.0->-r FPT/requirements.txt (line 5))\n  Downloading omegaconf-2.1.2-py3-none-any.whl.metadata (3.6 kB)\nCollecting antlr4-python3-runtime==4.8 (from hydra-core==1.1.0->-r FPT/requirements.txt (line 5))\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting importlib-resources (from hydra-core==1.1.0->-r FPT/requirements.txt (line 5))\n  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\nCollecting numpy (from torchvision==0.15.1->-r FPT/requirements.txt (line 7))\n  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nCollecting requests (from torchvision==0.15.1->-r FPT/requirements.txt (line 7))\n  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\nCollecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.15.1->-r FPT/requirements.txt (line 7))\n  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nCollecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.29.1->-r FPT/requirements.txt (line 8))\n  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\nCollecting packaging>=20.0 (from transformers==4.29.1->-r FPT/requirements.txt (line 8))\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting regex!=2019.12.17 (from transformers==4.29.1->-r FPT/requirements.txt (line 8))\n  Downloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.1->-r FPT/requirements.txt (line 8))\n  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: setuptools in /usr/local/envs/fpt_py38/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r FPT/requirements.txt (line 2)) (75.3.0)\nRequirement already satisfied: wheel in /usr/local/envs/fpt_py38/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r FPT/requirements.txt (line 2)) (0.45.1)\nCollecting cmake (from triton==2.0.0->torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading cmake-3.31.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nCollecting lit (from triton==2.0.0->torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\nCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.14.1->transformers==4.29.1->-r FPT/requirements.txt (line 8))\n  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\nCollecting tensorboard (from torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting psutil (from torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\nCollecting pyre-extensions (from torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading pyre_extensions-0.0.32-py3-none-any.whl.metadata (4.0 kB)\nCollecting tabulate (from torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\nCollecting zipp>=3.1.0 (from importlib-resources->hydra-core==1.1.0->-r FPT/requirements.txt (line 5))\n  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\nCollecting MarkupSafe>=2.0 (from jinja2->torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting charset-normalizer<4,>=2 (from requests->torchvision==0.15.1->-r FPT/requirements.txt (line 7))\n  Downloading charset_normalizer-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\nCollecting idna<4,>=2.5 (from requests->torchvision==0.15.1->-r FPT/requirements.txt (line 7))\n  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\nCollecting urllib3<3,>=1.21.1 (from requests->torchvision==0.15.1->-r FPT/requirements.txt (line 7))\n  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\nCollecting certifi>=2017.4.17 (from requests->torchvision==0.15.1->-r FPT/requirements.txt (line 7))\n  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\nCollecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.0->-r FPT/requirements.txt (line 2))\n  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\nCollecting typing-inspect (from pyre-extensions->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting absl-py>=0.4 (from tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting grpcio>=1.48.2 (from tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nCollecting google-auth<3,>=1.6.3 (from tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\nCollecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\nCollecting markdown>=2.6.8 (from tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\nCollecting protobuf>=3.19.6 (from tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\nCollecting werkzeug>=1.0.1 (from tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\nCollecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\nCollecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\nCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\nCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\nCollecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\nCollecting mypy-extensions>=0.3.0 (from typing-inspect->pyre-extensions->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\nCollecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\nCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval==0.0.6->-r FPT/requirements.txt (line 4))\n  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\nDownloading tqdm-4.50.2-py2.py3-none-any.whl (70 kB)\nDownloading torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 619.9/619.9 MB 13.4 MB/s eta 0:00:00\nDownloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 701.2/701.2 kB 25.9 MB/s eta 0:00:00\nDownloading torcheval-0.0.6-py3-none-any.whl (158 kB)\nDownloading hydra_core-1.1.0-py3-none-any.whl (144 kB)\nDownloading safetensors-0.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.3/1.3 MB 37.7 MB/s eta 0:00:00\nDownloading torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 33.8/33.8 MB 8.7 MB/s eta 0:00:00\nDownloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.1/7.1 MB 20.2 MB/s eta 0:00:00\nDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 317.1/317.1 MB 77.4 MB/s eta 0:00:00\nDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 11.8/11.8 MB 45.7 MB/s eta 0:00:00\nDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 21.0/21.0 MB 180.7 MB/s eta 0:00:00\nDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 849.3/849.3 kB 35.0 MB/s eta 0:00:00\nDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 557.1/557.1 MB 53.5 MB/s eta 0:00:00\nDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 168.4/168.4 MB 59.0 MB/s eta 0:00:00\nDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 54.6/54.6 MB 19.2 MB/s eta 0:00:00\nDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 102.6/102.6 MB 74.0 MB/s eta 0:00:00\nDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 173.2/173.2 MB 107.3 MB/s eta 0:00:00\nDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 177.1/177.1 MB 86.5 MB/s eta 0:00:00\nDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\nDownloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\nDownloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 63.2/63.2 MB 108.1 MB/s eta 0:00:00\nDownloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\nDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 17.3/17.3 MB 131.0 MB/s eta 0:00:00\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\nDownloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.5/4.5 MB 66.9 MB/s eta 0:00:00\nDownloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 785.1/785.1 kB 32.3 MB/s eta 0:00:00\nDownloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.8/7.8 MB 97.0 MB/s eta 0:00:00\nDownloading torchtnt-0.2.4-py3-none-any.whl (163 kB)\nDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\nDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\nDownloading jinja2-3.1.5-py3-none-any.whl (134 kB)\nDownloading networkx-3.1-py3-none-any.whl (2.1 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.1/2.1 MB 72.8 MB/s eta 0:00:00\nDownloading requests-2.32.3-py3-none-any.whl (64 kB)\nDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.2/6.2 MB 116.9 MB/s eta 0:00:00\nDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\nDownloading charset_normalizer-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\nDownloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\nDownloading idna-3.10-py3-none-any.whl (70 kB)\nDownloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\nDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 536.2/536.2 kB 17.3 MB/s eta 0:00:00\nDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\nDownloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\nDownloading cmake-3.31.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27.8/27.8 MB 104.2 MB/s eta 0:00:00\nDownloading lit-18.1.8-py3-none-any.whl (96 kB)\nDownloading psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\nDownloading pyre_extensions-0.0.32-py3-none-any.whl (12 kB)\nDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nDownloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.5/5.5 MB 78.0 MB/s eta 0:00:00\nDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\nDownloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\nDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\nDownloading grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.0/6.0 MB 89.0 MB/s eta 0:00:00\nDownloading Markdown-3.7-py3-none-any.whl (106 kB)\nDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\nDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.6/6.6 MB 107.5 MB/s eta 0:00:00\nDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\nDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nDownloading cachetools-5.5.1-py3-none-any.whl (9.5 kB)\nDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\nDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\nDownloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\nDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\nDownloading rsa-4.9-py3-none-any.whl (34 kB)\nDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\nDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\nBuilding wheels for collected packages: antlr4-python3-runtime\n  Building wheel for antlr4-python3-runtime (setup.py): started\n  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141213 sha256=60d034eb4adc6a9ea2d112c8a48351333835013779f6d6a501324d72f5132cb4\n  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\nSuccessfully built antlr4-python3-runtime\nInstalling collected packages: tokenizers, safetensors, mpmath, lit, antlr4-python3-runtime, zipp, urllib3, typing-extensions, tqdm, tensorboard-data-server, tabulate, sympy, regex, PyYAML, pyasn1, psutil, protobuf, pillow, packaging, oauthlib, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, mypy-extensions, MarkupSafe, idna, grpcio, fsspec, filelock, cmake, charset-normalizer, certifi, cachetools, absl-py, werkzeug, typing-inspect, rsa, requests, pyasn1-modules, omegaconf, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, importlib-resources, importlib-metadata, requests-oauthlib, pyre-extensions, markdown, hydra-core, huggingface-hub, google-auth, transformers, google-auth-oauthlib, tensorboard, triton, torch, torchtnt, torchvision, torcheval\nSuccessfully installed MarkupSafe-2.1.5 PyYAML-6.0 absl-py-2.1.0 antlr4-python3-runtime-4.8 cachetools-5.5.1 certifi-2025.1.31 charset-normalizer-3.4.1 cmake-3.31.4 filelock-3.16.1 fsspec-2025.2.0 google-auth-2.38.0 google-auth-oauthlib-1.0.0 grpcio-1.70.0 huggingface-hub-0.28.1 hydra-core-1.1.0 idna-3.10 importlib-metadata-8.5.0 importlib-resources-6.4.5 jinja2-3.1.5 lit-18.1.8 markdown-3.7 mpmath-1.3.0 mypy-extensions-1.0.0 networkx-3.1 numpy-1.24.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 oauthlib-3.2.2 omegaconf-2.1.2 packaging-24.2 pillow-10.4.0 protobuf-5.29.3 psutil-6.1.1 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyre-extensions-0.0.32 regex-2024.11.6 requests-2.32.3 requests-oauthlib-2.0.0 rsa-4.9 safetensors-0.3.2 sympy-1.13.3 tabulate-0.9.0 tensorboard-2.14.0 tensorboard-data-server-0.7.2 tokenizers-0.13.3 torch-2.0.0 torcheval-0.0.6 torchtnt-0.2.4 torchvision-0.15.1 tqdm-4.50.2 transformers-4.29.1 triton-2.0.0 typing-extensions-4.12.2 typing-inspect-0.9.0 urllib3-2.2.3 werkzeug-3.0.6 zipp-3.20.2\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!ls /kaggle/input/covid-cxr-image-dataset-research/COVID_IEEE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T15:13:07.320109Z","iopub.execute_input":"2025-02-01T15:13:07.320419Z","iopub.status.idle":"2025-02-01T15:13:07.451949Z","shell.execute_reply.started":"2025-02-01T15:13:07.320394Z","shell.execute_reply":"2025-02-01T15:13:07.451000Z"}},"outputs":[{"name":"stdout","text":"covid  normal  virus\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"!conda run -n fpt_py38 python FPT/split_dataset.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T16:18:30.603874Z","iopub.execute_input":"2025-02-01T16:18:30.604232Z","iopub.status.idle":"2025-02-01T16:18:44.731133Z","shell.execute_reply.started":"2025-02-01T16:18:30.604196Z","shell.execute_reply":"2025-02-01T16:18:44.729951Z"}},"outputs":[{"name":"stdout","text":"Class: covid | Total: 536 | Train: 375 | Val: 53 | Test: 108\nClass: normal | Total: 668 | Train: 467 | Val: 66 | Test: 135\nClass: virus | Total: 619 | Train: 433 | Val: 61 | Test: 125\nDataset split completed successfully!\n\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"!ls ./COVID_IEEE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T16:18:42.368102Z","iopub.execute_input":"2025-02-02T16:18:42.368444Z","iopub.status.idle":"2025-02-02T16:18:42.491604Z","shell.execute_reply.started":"2025-02-02T16:18:42.368412Z","shell.execute_reply":"2025-02-02T16:18:42.490633Z"}},"outputs":[{"name":"stdout","text":"test  train  val\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!conda run -n fpt_py38 python FPT/preload.py dataset=covid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T16:18:54.597978Z","iopub.execute_input":"2025-02-01T16:18:54.598360Z","iopub.status.idle":"2025-02-01T16:21:01.852627Z","shell.execute_reply.started":"2025-02-01T16:18:54.598327Z","shell.execute_reply":"2025-02-01T16:21:01.851258Z"}},"outputs":[{"name":"stdout","text":"Preloading covid dataset...\nPreloading train dataset...\nPreloading test dataset...\nPreloading val dataset...\nPreloading done.\n\n/usr/local/envs/fpt_py38/lib/python3.8/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/usr/local/envs/fpt_py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:21<00:00,  1.07s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:25<00:00,  1.16s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:12<00:00,  1.14s/it]\n\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"!conda run -n fpt_py38 python FPT/main.py dataset=covid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T16:18:46.768392Z","iopub.execute_input":"2025-02-02T16:18:46.768764Z","iopub.status.idle":"2025-02-02T16:34:38.061749Z","shell.execute_reply.started":"2025-02-02T16:18:46.768734Z","shell.execute_reply":"2025-02-02T16:34:38.060948Z"}},"outputs":[{"name":"stdout","text":"===================\nLOADING CONFIG FILE\n===================\nbase:\n  device: cuda:0\n  random_seed: -1\n  cudnn_deterministic: false\n  overwrite: false\n  progress: true\n  checkpoint: null\nnetwork:\n  num_prompts: 16\n  side_reduction_ratio: 8\n  prompt_reduction_ratio: 1\n  prompt_norm: true\n  prompt_proj: false\n  layers_to_extract: 6-11\n  token_ratio: 0.2\n  token_imp: global\n  side_input_size: 128\n  pretrained_path: google/vit-base-patch16-384\ndataset:\n  name: covid\n  data_path: /kaggle/working/COVID_IEEE\n  preload_path: /kaggle/working/covid_preload_data\n  save_path: /kaggle/working/covid_runs\n  input_size: 512\n  num_classes: 3\n  mean:\n  - 0.498341828584671\n  - 0.4986386299133301\n  - 0.49894729256629944\n  std:\n  - 0.2426202893257141\n  - 0.24259139597415924\n  - 0.242642343044281\n  learning_rate: 0.0001\nsolver:\n  optimizer: ADAMW\n  weight_decay: 0.1\n  betas:\n  - 0.9\n  - 0.999\ndata_augmentation_args:\n  horizontal_flip:\n    prob: 0.5\n  vertical_flip:\n    prob: 0.5\n  color_distortion:\n    prob: 1.0\n    brightness: 0.2\n    contrast: 0.2\n    saturation: 0\n    hue: 0\n  random_crop:\n    prob: 1.0\n    scale:\n    - 0.8\n    - 1.0\n    ratio:\n    - 0.7\n    - 1.3\n  rotation:\n    prob: 1.0\n    degrees:\n    - -30\n    - 30\n  translation:\n    prob: 1\n    range:\n    - 0.2\n    - 0.2\n  grayscale:\n    prob: 0.2\n  gaussian_blur:\n    prob: 0.2\n    kernel_size: 7\n    sigma: 0.1\n  value_fill: 0\ntrain:\n  epochs: 20\n  batch_size: 16\n  num_workers: 16\n  criterion: cross_entropy\n  loss_weight: null\n  loss_weight_decay_rate: 0\n  warmup_epochs: 0\n  metrics:\n  - acc\n  - f1\n  - auc\n  - precision\n  - recall\n  - kappa\n  indicator: auc\n  save_interval: 10\n  eval_interval: 1\n  sample_view: false\n  pin_memory: true\n\n\u001b[93m================================================================================\u001b[0m\n\u001b[93mSave path /kaggle/working/covid_runs exists. New save path is set to be /kaggle/working/covid_runs_1.\u001b[0m\n\u001b[93m================================================================================\u001b[0m\ncfg.dataset.preload_path = /kaggle/working/covid_preload_data\n==============================================================\nPreloading is enabled using /kaggle/working/covid_preload_data\n==============================================================\n=========================\nDataset Loaded.\nCategories:\t3\nTraining:\t1201\nValidation:\t163\nTest:\t\t344\n=========================\nTraining metrics: acc: 0.7383, f1: 0.7383, auc: 0.8846, precision: 0.7383, recall: 0.7383, kappa: 0.5992\n===================\nValidation metrics:\nacc: 0.920245\nf1: 0.920245\nauc: 0.991979\nprecision: 0.920245\nrecall: 0.920245\nkappa: 0.901417\n===================\n======================================================================\nModel saved at /kaggle/working/covid_runs_1/best_validation_weights.pt\n======================================================================\nTraining metrics: acc: 0.95, f1: 0.95, auc: 0.9831, precision: 0.95, recall: 0.95, kappa: 0.9307\n===================\nValidation metrics:\nacc: 0.96319\nf1: 0.96319\nauc: 0.991424\nprecision: 0.96319\nrecall: 0.96319\nkappa: 0.934956\n===================\nTraining metrics: acc: 0.9508, f1: 0.9508, auc: 0.9886, precision: 0.9508, recall: 0.9508, kappa: 0.9399\n===================\nValidation metrics:\nacc: 0.93865\nf1: 0.93865\nauc: 0.987444\nprecision: 0.93865\nrecall: 0.93865\nkappa: 0.913922\n===================\nTraining metrics: acc: 0.9783, f1: 0.9783, auc: 0.9929, precision: 0.9783, recall: 0.9783, kappa: 0.9715\n===================\nValidation metrics:\nacc: 0.932515\nf1: 0.932515\nauc: 0.984265\nprecision: 0.932515\nrecall: 0.932515\nkappa: 0.894757\n===================\nTraining metrics: acc: 0.9833, f1: 0.9833, auc: 0.9948, precision: 0.9833, recall: 0.9833, kappa: 0.9798\n===================\nValidation metrics:\nacc: 0.969325\nf1: 0.969325\nauc: 0.987144\nprecision: 0.969325\nrecall: 0.969325\nkappa: 0.973178\n===================\nTraining metrics: acc: 0.9858, f1: 0.9858, auc: 0.9966, precision: 0.9858, recall: 0.9858, kappa: 0.9882\n===================\nValidation metrics:\nacc: 0.95092\nf1: 0.95092\nauc: 0.985587\nprecision: 0.95092\nrecall: 0.95092\nkappa: 0.957558\n===================\nTraining metrics: acc: 0.9917, f1: 0.9917, auc: 0.9977, precision: 0.9917, recall: 0.9917, kappa: 0.9889\n===================\nValidation metrics:\nacc: 0.969325\nf1: 0.969325\nauc: 0.983544\nprecision: 0.969325\nrecall: 0.969325\nkappa: 0.972977\n===================\nTraining metrics: acc: 0.9917, f1: 0.9917, auc: 0.9993, precision: 0.9917, recall: 0.9917, kappa: 0.993\n===================\nValidation metrics:\nacc: 0.95092\nf1: 0.95092\nauc: 0.983239\nprecision: 0.95092\nrecall: 0.95092\nkappa: 0.957243\n===================\nTraining metrics: acc: 0.9925, f1: 0.9925, auc: 0.9997, precision: 0.9925, recall: 0.9925, kappa: 0.9937\n===================\nValidation metrics:\nacc: 0.92638\nf1: 0.92638\nauc: 0.985575\nprecision: 0.92638\nrecall: 0.92638\nkappa: 0.922418\n===================\nTraining metrics: acc: 0.9942, f1: 0.9942, auc: 0.9994, precision: 0.9942, recall: 0.9942, kappa: 0.9951\n===================\nValidation metrics:\nacc: 0.95092\nf1: 0.95092\nauc: 0.992186\nprecision: 0.95092\nrecall: 0.95092\nkappa: 0.958003\n===================\n======================================================================\nModel saved at /kaggle/working/covid_runs_1/best_validation_weights.pt\n======================================================================\nTraining metrics: acc: 0.9958, f1: 0.9958, auc: 0.9995, precision: 0.9958, recall: 0.9958, kappa: 0.9944\n===================\nValidation metrics:\nacc: 0.957055\nf1: 0.957055\nauc: 0.985252\nprecision: 0.957055\nrecall: 0.957055\nkappa: 0.946947\n===================\nTraining metrics: acc: 0.9967, f1: 0.9967, auc: 0.9999, precision: 0.9967, recall: 0.9967, kappa: 0.9972\n===================\nValidation metrics:\nacc: 0.957055\nf1: 0.957055\nauc: 0.984936\nprecision: 0.957055\nrecall: 0.957055\nkappa: 0.946554\n===================\nTraining metrics: acc: 0.9983, f1: 0.9983, auc: 0.9999, precision: 0.9983, recall: 0.9983, kappa: 0.9986\n===================\nValidation metrics:\nacc: 0.957055\nf1: 0.957055\nauc: 0.9838\nprecision: 0.957055\nrecall: 0.957055\nkappa: 0.946947\n===================\nTraining metrics: acc: 0.9975, f1: 0.9975, auc: 1.0, precision: 0.9975, recall: 0.9975, kappa: 0.9979\n===================\nValidation metrics:\nacc: 0.93865\nf1: 0.93865\nauc: 0.984447\nprecision: 0.93865\nrecall: 0.93865\nkappa: 0.931784\n===================\nTraining metrics: acc: 0.9983, f1: 0.9983, auc: 1.0, precision: 0.9983, recall: 0.9983, kappa: 0.9986\n===================\nValidation metrics:\nacc: 0.93865\nf1: 0.93865\nauc: 0.984396\nprecision: 0.93865\nrecall: 0.93865\nkappa: 0.931784\n===================\nTraining metrics: acc: 0.9983, f1: 0.9983, auc: 1.0, precision: 0.9983, recall: 0.9983, kappa: 0.9986\n===================\nValidation metrics:\nacc: 0.93865\nf1: 0.93865\nauc: 0.983838\nprecision: 0.93865\nrecall: 0.93865\nkappa: 0.931784\n===================\nTraining metrics: acc: 0.9983, f1: 0.9983, auc: 1.0, precision: 0.9983, recall: 0.9983, kappa: 0.9986\n===================\nValidation metrics:\nacc: 0.93865\nf1: 0.93865\nauc: 0.984277\nprecision: 0.93865\nrecall: 0.93865\nkappa: 0.931784\n===================\nTraining metrics: acc: 0.9983, f1: 0.9983, auc: 1.0, precision: 0.9983, recall: 0.9983, kappa: 0.9986\n===================\nValidation metrics:\nacc: 0.93865\nf1: 0.93865\nauc: 0.984695\nprecision: 0.93865\nrecall: 0.93865\nkappa: 0.931784\n===================\nTraining metrics: acc: 0.9983, f1: 0.9983, auc: 1.0, precision: 0.9983, recall: 0.9983, kappa: 0.9986\n===================\nValidation metrics:\nacc: 0.93865\nf1: 0.93865\nauc: 0.984747\nprecision: 0.93865\nrecall: 0.93865\nkappa: 0.931784\n===================\nTraining metrics: acc: 0.9983, f1: 0.9983, auc: 1.0, precision: 0.9983, recall: 0.9983, kappa: 0.9986\n===================\nValidation metrics:\nacc: 0.93865\nf1: 0.93865\nauc: 0.984747\nprecision: 0.93865\nrecall: 0.93865\nkappa: 0.931784\n===================\n============================================================\nModel saved at /kaggle/working/covid_runs_1/final_weights.pt\n============================================================\nThis is the performance of the final model:\n===============================================================\nLoad weights form /kaggle/working/covid_runs_1/final_weights.pt\n===============================================================\nRunning on Test set...\n================Finished================\nacc: 0.968023\nf1: 0.968023\nauc: 0.989711\nprecision: 0.968023\nrecall: 0.968023\nkappa: 0.973073\nConfusion Matrix:\n[[ 83   1   0]\n [  0 129   6]\n [  0   4 121]]\n========================================\nThis is the performance of the best validation model:\n=========================================================================\nLoad weights form /kaggle/working/covid_runs_1/best_validation_weights.pt\n=========================================================================\nRunning on Test set...\n================Finished================\nacc: 0.973837\nf1: 0.973837\nauc: 0.985952\nprecision: 0.973837\nrecall: 0.973837\nkappa: 0.977886\nConfusion Matrix:\n[[ 83   1   0]\n [  0 131   4]\n [  0   4 121]]\n========================================\n\n/usr/local/envs/fpt_py38/lib/python3.8/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/usr/local/envs/fpt_py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\nepoch: [1 / 20], cls_loss: 0.640824, lr: 0.0001: : 75it [00:52,  1.42it/s]\nepoch: [2 / 20], cls_loss: 0.228248, lr: 0.0001: : 75it [00:45,  1.63it/s]\nepoch: [3 / 20], cls_loss: 0.174604, lr: 0.0001: : 75it [00:42,  1.76it/s]\nepoch: [4 / 20], cls_loss: 0.109640, lr: 0.0001: : 75it [00:42,  1.79it/s]\nepoch: [5 / 20], cls_loss: 0.080104, lr: 0.0001: : 75it [00:42,  1.77it/s]\nepoch: [6 / 20], cls_loss: 0.066387, lr: 0.0001: : 75it [00:41,  1.80it/s]\nepoch: [7 / 20], cls_loss: 0.042737, lr: 0.0001: : 75it [00:42,  1.77it/s]\nepoch: [8 / 20], cls_loss: 0.043086, lr: 0.0001: : 75it [00:41,  1.80it/s]\nepoch: [9 / 20], cls_loss: 0.038082, lr: 0.0001: : 75it [00:41,  1.79it/s]\nepoch: [10 / 20], cls_loss: 0.026355, lr: 0.0001: : 75it [00:41,  1.82it/s]\nepoch: [11 / 20], cls_loss: 0.028192, lr: 0.0000: : 75it [00:42,  1.78it/s]\nepoch: [12 / 20], cls_loss: 0.018100, lr: 0.0000: : 75it [00:42,  1.77it/s]\nepoch: [13 / 20], cls_loss: 0.013943, lr: 0.0000: : 75it [00:42,  1.77it/s]\nepoch: [14 / 20], cls_loss: 0.014626, lr: 0.0000: : 75it [00:41,  1.79it/s]\nepoch: [15 / 20], cls_loss: 0.012521, lr: 0.0000: : 75it [00:41,  1.82it/s]\nepoch: [16 / 20], cls_loss: 0.011314, lr: 0.0000: : 75it [00:41,  1.79it/s]\nepoch: [17 / 20], cls_loss: 0.011101, lr: 0.0000: : 75it [00:42,  1.78it/s]\nepoch: [18 / 20], cls_loss: 0.011400, lr: 0.0000: : 75it [00:41,  1.81it/s]\nepoch: [19 / 20], cls_loss: 0.007794, lr: 0.0000: : 75it [00:42,  1.78it/s]\nepoch: [20 / 20], cls_loss: 0.010358, lr: 0.0000: : 75it [00:41,  1.82it/s]\n\n","output_type":"stream"}],"execution_count":4}]}